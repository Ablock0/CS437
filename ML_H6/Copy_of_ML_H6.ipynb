{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ML.H6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ablock0/CS437/blob/master/Copy_of_ML_H6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F-VbRXjONkp",
        "colab_type": "text"
      },
      "source": [
        "# **Homework Assignment #6**\n",
        "\n",
        "Assigned: April 2, 2020\n",
        "\n",
        "Due: April 21, 2020\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "This assignment consists of questions that require a short answer and one Python programming task. You can enter your answers and your code directly in a Colaboratory notebook and upload the **shareable** link for your notebook as your homework submission.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#1.\n",
        "\n",
        " (12 points) Both PCA and linear regression can be thought of as algorithms for minimizing a sum of squared errors. Provide formulas and explain which error is being minimized in each algorithm.\n",
        "\n",
        "\n",
        "#-> ANSWER \n",
        "\n",
        "The formula for PCA will find a set of vectors that will work to minimize the projection error\n",
        "of each points onto the new set of vectors. This will redcue the dimensionality of the dataset.\n",
        "<br>\n",
        "Formula:\n",
        "1. Shift the dataset to be centered at the origin\n",
        "2. Find a vector (or set of vectors) that points in the directional of maximum variance / minimum\n",
        "projection error (they are the same)\n",
        "\n",
        "Linear Regression aims to find the line will minimize the cost function, which is based upon the\n",
        "difference between the predicted and actual values of the dataset.\n",
        "<br>\n",
        "Formula:\n",
        "a_0 = a_0 - alpha * (2/n) (summation from i=1 to n of (pred_i - y_i))\n",
        "\n",
        "---\n",
        "\n",
        "#2.\n",
        "\n",
        "(16 points) Consider the robot gridworld Markov Decision Process (MDP) shown below. States are numbered s1 through s6, transitions are indicated by arrows and have probability = 1, immediate rewards are assigned to specific transitions, and transitions with no label have an immediate reward of 0. Assume the discount factor $\\gamma = 0.8$ and $\\alpha=0.5$.\n",
        "\n",
        "![](https://drive.google.com/uc?id=1O6hVYZO2SmG7uXb9xPLpyN0RAnylZkaA)\n",
        "\n",
        "For each state $s$, write the value for $V*(s)$ inside the corresponding square in the diagram. These values should be consistent with the reward values shown in the figures and with the discount factor.\n",
        "\n",
        "Make the state-action transition arrows that correspond to one optimal policy. If there is a tie, choose the state with the smaller number.\n",
        "\n",
        "Provide a different value for $\\gamma$ which results in a different optimal policy. Describe the resulting policy by indicating which $\\pi(s)$ values change (i.e., which policy actions change).\n",
        "\n",
        "Starting with initial values of 0, simulate two iterations of q-learning starting from state s1 and selecting a sequence of 3 actions per iteration (sequences that force changes to Q values, such as \\{right, right, stay\\}. Show the updated q(s,a) values after each iteration.\n",
        "\n",
        "\n",
        "#-> ANSWER\n",
        "\n",
        "refer to the diagram attached with this github link\n",
        "\n",
        "---\n",
        "\n",
        "#3.\n",
        "\n",
        "(100 points) Use Keras and TensorFlow to design and compare four different convolutional neural networks to recognize MNIST digits. The MNIST dataset is provided as part of Keras. You can design the network structures as you like but each one should differ in both structure (number and ordering of convolution, ReLU, and pooling layers) and parameter values. Provide a brief justification of each network and summarize the performance\n",
        "of the alternative network structures.\n",
        "\n",
        "#-> ANSWER\n",
        "reponses are written after each of the CNN variations below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXcfH7s7ERM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#installing tensor flow\n",
        "!pip install tensorflow-gpu==2.0.0-alpha0\n",
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmDwAjrOJCl4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "882ae278-3e80-47a1-ac52-9922c7e1e7ad"
      },
      "source": [
        "#ALL GIVEN CODE FROM IN CLASS PORTION\n",
        "\n",
        "#imports\n",
        "from tensorflow.python import keras\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255.\n",
        "\n",
        "%matplotlib inline\n",
        "# plot three of the instances\n",
        "fig, axes = plt.subplots(1,3)\n",
        "for i in range(3):\n",
        "    img = x_train[i, :, :]\n",
        "    axes[i].set_title(\"Label: %d\" % y_train[i])\n",
        "    axes[i].imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Training Set Data (X): \", x_train.shape)\n",
        "print(\"Training Set Labels (Y): \", y_train.shape)\n",
        "print(\"Testing Set Data (X): \", x_test.shape)\n",
        "print(\"Testing Set Labels (Y): \", y_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training Set Data (X):  (60000, 28, 28)\n",
            "Training Set Labels (Y):  (60000,)\n",
            "Testing Set Data (X):  (10000, 28, 28)\n",
            "Testing Set Labels (Y):  (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-KnvhHeKXF7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "a91bc761-dbbe-4274-cbb5-ba9425511e76"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.fit(\n",
        "    x=x_train, y=y_train, epochs=5\n",
        ")\n",
        "\n",
        "y_pred = model.predict_classes(x=x_test)\n",
        "print(\"Test Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, target_names=[\n",
        "    '%d' % i for i in range(10)\n",
        "], digits=5))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2609 - accuracy: 0.9268\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1158 - accuracy: 0.9657\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0788 - accuracy: 0.9757\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0587 - accuracy: 0.9825\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0448 - accuracy: 0.9863\n",
            "Test Accuracy:  0.974\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.96813   0.99184   0.97984       980\n",
            "           1    0.99464   0.98150   0.98803      1135\n",
            "           2    0.98898   0.95640   0.97241      1032\n",
            "           3    0.94057   0.98713   0.96329      1010\n",
            "           4    0.96223   0.98574   0.97384       982\n",
            "           5    0.99076   0.96188   0.97611       892\n",
            "           6    0.98211   0.97390   0.97799       958\n",
            "           7    0.98221   0.96693   0.97451      1028\n",
            "           8    0.96395   0.96099   0.96247       974\n",
            "           9    0.96841   0.97225   0.97033      1009\n",
            "\n",
            "    accuracy                        0.97400     10000\n",
            "   macro avg    0.97420   0.97386   0.97388     10000\n",
            "weighted avg    0.97435   0.97400   0.97403     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLx8KllfStqk",
        "colab_type": "text"
      },
      "source": [
        "This model did better than I thought it would. I did not add any pooling or any convolution to this model and it still came out as my 3rd most accurate model at a 97.4% accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf9tviAgPcuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "34d633a9-8465-4307-e348-12a9d7dc0920"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.fit(\n",
        "    x=x_train, y=y_train, epochs=5\n",
        ")\n",
        "\n",
        "y_pred = model.predict_classes(x=x_test)\n",
        "print(\"Test Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, target_names=[\n",
        "    '%d' % i for i in range(10)\n",
        "], digits=5))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 30s 500us/sample - loss: 0.1619 - accuracy: 0.9532\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 30s 500us/sample - loss: 0.0581 - accuracy: 0.9822\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 30s 497us/sample - loss: 0.0390 - accuracy: 0.9879\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 30s 498us/sample - loss: 0.0273 - accuracy: 0.9916\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 30s 505us/sample - loss: 0.0196 - accuracy: 0.9934\n",
            "Test Accuracy:  0.9868\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.98584   0.99490   0.99035       980\n",
            "           1    0.99125   0.99824   0.99473      1135\n",
            "           2    0.98929   0.98450   0.98689      1032\n",
            "           3    0.98327   0.98911   0.98618      1010\n",
            "           4    0.97898   0.99593   0.98738       982\n",
            "           5    0.98656   0.98767   0.98711       892\n",
            "           6    0.99261   0.98121   0.98688       958\n",
            "           7    0.98729   0.98249   0.98489      1028\n",
            "           8    0.98560   0.98357   0.98458       974\n",
            "           9    0.98688   0.96928   0.97800      1009\n",
            "\n",
            "    accuracy                        0.98680     10000\n",
            "   macro avg    0.98676   0.98669   0.98670     10000\n",
            "weighted avg    0.98682   0.98680   0.98679     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRVZSntPS_VA",
        "colab_type": "text"
      },
      "source": [
        "I copied the same model as above but I wanted to see how much more accurate it would become if i only added a single layer of both convolution and pooling. The accuracy did in fact go up by a fairly significant margin, increasing from the previous 97.4% to this model's 98.68% accuracy. The biggest, and most annoying difference that I noticed immediatly was how much more time this model took to compile each epoch compared to the previous one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUbtxaQHRQe_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "42e28829-af36-43ee-cc6d-d67df605312a"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "x_train = x_train.reshape((60000, 28, 28, 1))\n",
        "x_test = x_test.reshape((10000, 28, 28, 1))\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.fit(\n",
        "    x=x_train, y=y_train, epochs=5\n",
        ")\n",
        "\n",
        "y_pred = model.predict_classes(x=x_test)\n",
        "print(\"Test Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, target_names=[\n",
        "    '%d' % i for i in range(10)\n",
        "], digits=5))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 12s 193us/sample - loss: 0.3463 - accuracy: 0.8978\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 11s 190us/sample - loss: 0.1339 - accuracy: 0.9577\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 12s 192us/sample - loss: 0.1098 - accuracy: 0.9653\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 11s 191us/sample - loss: 0.0953 - accuracy: 0.9698\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 11s 190us/sample - loss: 0.0849 - accuracy: 0.9728\n",
            "Test Accuracy:  0.9734\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.97009   0.99286   0.98134       980\n",
            "           1    0.99286   0.98062   0.98670      1135\n",
            "           2    0.98431   0.97287   0.97856      1032\n",
            "           3    0.94134   0.98515   0.96275      1010\n",
            "           4    0.98753   0.96741   0.97737       982\n",
            "           5    0.99407   0.93946   0.96599       892\n",
            "           6    0.99051   0.98017   0.98531       958\n",
            "           7    0.95829   0.98346   0.97072      1028\n",
            "           8    0.95176   0.97228   0.96191       974\n",
            "           9    0.96787   0.95540   0.96160      1009\n",
            "\n",
            "    accuracy                        0.97340     10000\n",
            "   macro avg    0.97386   0.97297   0.97322     10000\n",
            "weighted avg    0.97382   0.97340   0.97343     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQJub25TTjRu",
        "colab_type": "text"
      },
      "source": [
        "For this model, I wanted to test how each individual aspect affected the accuracy, specifically here I decided to add the pooling layer first, followed by a single convolution layer, then adding 2 more pooling layers after. This was to mainly test the affect of ordering and pooling on the model. The time for each epoch to complete was much better than the last model, but this model started off MUCH less accurate within the first epoch. The model then quickly learned between epochs, but was still my least accurate of the 4 models at only 97.34%. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvZtLDNENy4B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "422a0349-7dac-46cf-aeaf-6211fbe2995d"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "x_train = x_train.reshape((60000, 28, 28, 1))\n",
        "x_test = x_test.reshape((10000, 28, 28, 1))\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.fit(\n",
        "    x=x_train, y=y_train, epochs=5\n",
        ")\n",
        "\n",
        "y_pred = model.predict_classes(x=x_test)\n",
        "print(\"Test Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, target_names=[\n",
        "    '%d' % i for i in range(10)\n",
        "], digits=5))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 55s 919us/sample - loss: 0.1444 - accuracy: 0.9546\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 54s 901us/sample - loss: 0.0467 - accuracy: 0.9855\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 53s 889us/sample - loss: 0.0341 - accuracy: 0.9895\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 54s 898us/sample - loss: 0.0252 - accuracy: 0.9919\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 55s 910us/sample - loss: 0.0197 - accuracy: 0.9938\n",
            "Test Accuracy:  0.9888\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.98988   0.99796   0.99390       980\n",
            "           1    0.99383   0.99383   0.99383      1135\n",
            "           2    0.99803   0.98062   0.98925      1032\n",
            "           3    0.96824   0.99604   0.98194      1010\n",
            "           4    0.98788   0.99593   0.99189       982\n",
            "           5    0.99090   0.97646   0.98363       892\n",
            "           6    0.99684   0.98852   0.99266       958\n",
            "           7    0.97148   0.99416   0.98269      1028\n",
            "           8    0.99791   0.98255   0.99017       974\n",
            "           9    0.99497   0.98018   0.98752      1009\n",
            "\n",
            "    accuracy                        0.98880     10000\n",
            "   macro avg    0.98900   0.98862   0.98875     10000\n",
            "weighted avg    0.98895   0.98880   0.98881     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FurbrNXeUE3W",
        "colab_type": "text"
      },
      "source": [
        "For my final model, I decided to add multiple layers of convolution and pooling together, as well as adjusting the parameter of the convolution from 32 to 64 to see how accurate i could make the model. This model took an insanely large amount of time to finish each epoch, at almost a full minute per, however it also turned out to be my most accurate model by only .2%! This model finished at an overall 98.88% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BKHveQ1UiGg",
        "colab_type": "text"
      },
      "source": [
        "As a summary, i think it is fairly obvious that the order of the pooling and convolution can have an affect on accuracy in the overall model. Also, it is clear within the final model that adding multiple layers to our CNN will make it more and more accurate, however you will need to keep an eye on the amount of time each epoch will take as you add on more and more layers. A balance for accuracy and resource consumption will need to be found if you are to do larger tests."
      ]
    }
  ]
}